{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a biGRU neural network model\n",
    "\n",
    "In this notebook, we are going to build a bidirectional Gated Recurrent Unit neural network model, in which we will implement and use the following architectures and tools:\n",
    "- Bidirectional GRU\n",
    "- Multi-layer (stacked) GRU\n",
    "- Dropout\n",
    "- Spatial Dropout after embedding layer\n",
    "- Max-pooling\n",
    "- Average-pooling\n",
    "- pack_padded_sequence\n",
    "\n",
    "The model is going to be trained on the clean_review column from the training dataset, other features will be used in the next notebook. In the end, the model will be evaluated on the test set to determine the generalization error.\n",
    "\n",
    "We will perform the hyperparameter fine-tuning and visualize model's learning curves to compare the model's performance while working on different set of parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gated Recurrent Unit\n",
    "Gated Recurrent Unit is the simpler variation of the LSTM (Long-Short Term Memory). Both these architectures were proposed as the remedy for the RNN's vanishing gradient problems. GRU comprised of only two gates, while its ancestor - LSTM had 3 gates in its unit, thus the GRU unit that was firstly introduced by the Kyunghyun Cho in the following paper:\n",
    "https://arxiv.org/pdf/1406.1078v3.pdf, is much simpler to compute and implement.\n",
    "<br><br>\n",
    "The GRU consists of two gates:\n",
    "- Update  gate *z* that selects whether  the  hidden  state  is  to  be  updated  with a  new  hidden  state Ìƒ*h*.\n",
    "- Reset  gate *r* that decides whether the previous hidden state is ignored.\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/GRU_shema.png\" width=\"400\" />\n",
    "</div>\n",
    "\n",
    "<p style='text-align: center;'>GRU shema [By Jeblad - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=66225938]</p>\n",
    "\n",
    "For each element in the input sequence, each layer computes the following function:<br><br>\n",
    "$ r_t = sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr})$<br>\n",
    "$ z_t = sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz})$<br>\n",
    "$ `h_t = tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn}))$<br>\n",
    "$ h_t = (1 - z_t) * `h_t + z_t * h_{(t-1)}$\n",
    "<br>\n",
    "\n",
    "#### Bidirectional RNN\n",
    "Bidirectional Recurrent Neural Network consists of two recurrent hidden layers, that have opposite direction, in other words, one layer reads the sequence from the beginning to the end, while the other one reads it in reverse order. This architecture provides the model with much more information, as it includes both past and future context.<br>\n",
    "<div>\n",
    "<img src=\"assets/RNN-bidirectional.png\" width=\"400\" />\n",
    "</div>\n",
    "\n",
    "<p style='text-align: center;'>Bidirectional RNN schema [http://colah.github.io/posts/2015-09-NN-Types-FP/]</p>\n",
    "<br>\n",
    "Another concept that is worth to mention is the <b>stacked RNN</b> that simply consists of two or more hidden layers stacked together.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Spatial dropout\n",
    "\n",
    "Spatial dropout is another method of using dropout regularization that is applied most commonly in Convolutional Neural Networks. In contrast to the traditional dropout, the spatial dropout zeroes out the entire 1D feature map from the embedding feature vector of each word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model's architecture\n",
    "\n",
    "The graph of the model created using tensorboardX is depicted below.<br>\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/BiGRU_model_graph.png\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot is going on the above plot, so for the sake of simplicity, I have created an additional schema that shows the layout of the model.\n",
    "<br>\n",
    "<br>\n",
    "<div>\n",
    "<img src=\"assets/BiGRU_schema.png\" width=\"750\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the GRU layer we will concatenate both, the average pooling and max pooling of the hidden representation and the last hidden state of GRU in order to prevent our model from forgetting infromations. This architecture is described in the following paper: https://arxiv.org/pdf/1801.06146.pdf. There is also the possibility to get rid of the last hidden state from our model at all, this kind of architecture, that uses max-pooling or avg-pooling is depicted in the paper: https://arxiv.org/pdf/1705.02364.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and training the model\n",
    "\n",
    "Let's start with importing all indispensable libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_iterator import BatchIterator\n",
    "from early_stopping import EarlyStopping\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import device\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to load the tarining and validation sets, but we will use only the clean_review column and label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset. Use clean_review and label columns\n",
    "train_dataset = pd.read_csv('dataset/drugreview_feat_clean/train_feat_clean.csv', \n",
    "                            usecols=['clean_review', 'rating'])\n",
    "\n",
    "# Change columns order\n",
    "train_dataset['label'] = train_dataset.rating >= 5\n",
    "train_dataset = train_dataset[['clean_review', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>young suffering severe extreme neck pain resul...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>found work helping good nights sleep don&amp;#039;...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>given medication gastroenterologist office wor...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>recently laparoscopic hysterectomy know anesth...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>mirena year experienced effects effects watch ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_review  label\n",
       "2   young suffering severe extreme neck pain resul...   True\n",
       "5   found work helping good nights sleep don&#039;...   True\n",
       "9   given medication gastroenterologist office wor...  False\n",
       "12  recently laparoscopic hysterectomy know anesth...   True\n",
       "13  mirena year experienced effects effects watch ...  False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depict the first 5 rows of the training set\n",
    "train_dataset = train_dataset.dropna()\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset. Use clean_review and label columns\n",
    "val_dataset = pd.read_csv('dataset/drugreview_feat_clean/val_feat_clean.csv',\n",
    "                          usecols=['clean_review', 'rating'])\n",
    "\n",
    "# Change columns order\n",
    "\n",
    "val_dataset['label'] = val_dataset.rating >= 5\n",
    "val_dataset = val_dataset[['clean_review', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>year old son took night went deep sea fishing ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>daughter epiduo grade junior year work wonders...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i&amp;#039;ve implant months day got totally felt ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>wanted wait days post couldn&amp;#039;t results am...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>colonoscopy best prep far morning took prep pm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        clean_review  label\n",
       "0  year old son took night went deep sea fishing ...   True\n",
       "1  daughter epiduo grade junior year work wonders...   True\n",
       "2  i&#039;ve implant months day got totally felt ...   True\n",
       "3  wanted wait days post couldn&#039;t results am...   True\n",
       "4  colonoscopy best prep far morning took prep pm...   True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depict the first 5 rows of the validation set\n",
    "val_dataset = val_dataset.dropna()\n",
    "val_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will use the BatchIterator class defined in the previous notebook to create the vocabulary, trim sequences in terms of the rare word occurrence and the length, map words to their numerical representation (word2index), furthermore BatchIterator sorts dataset examples, generates batches, performs sequence padding and enables to use it instance to iterate through all batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed vocabulary using as minimum count threashold: count = 3.00\n",
      "8674/21861 tokens has been retained\n",
      "Trimmed input strings vocabulary\n",
      "Trimmed input sequences lengths to the length of: 58\n",
      "Mapped words to indices\n",
      "Batches created\n"
     ]
    }
   ],
   "source": [
    "train_iterator = BatchIterator(train_dataset, batch_size=256, vocab_created=False, vocab=None, target_col=None,\n",
    "                               word2index=None, sos_token='<SOS>', eos_token='<EOS>', unk_token='<UNK>',\n",
    "                               pad_token='<PAD>', min_word_count=3, max_vocab_size=None, max_seq_len=0.9,\n",
    "                               use_pretrained_vectors=False, glove_path='glove/', glove_name='glove.6B.100d.txt',\n",
    "                               weights_file_name='glove/weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed vocabulary using as minimum count threashold: count = 3.00\n",
      "4655/11853 tokens has been retained\n",
      "Trimmed input strings vocabulary\n",
      "Trimmed input sequences lengths to the length of: 57\n",
      "Mapped words to indices\n",
      "Batches created\n"
     ]
    }
   ],
   "source": [
    "val_iterator = BatchIterator(val_dataset, batch_size=256, vocab_created=False, vocab=None, target_col=None,\n",
    "                             word2index=train_iterator.word2index, sos_token='<SOS>', eos_token='<EOS>',\n",
    "                             unk_token='<UNK>', pad_token='<PAD>', min_word_count=3, max_vocab_size=None,\n",
    "                             max_seq_len=0.9, use_pretrained_vectors=False, glove_path='glove/',\n",
    "                             glove_name='glove.6B.100d.txt', weights_file_name='glove/weights.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to check out how batches that we created look like before we pass them into the model. For the record, the set of batches for input and output variables is returned as a dictionary, thus we will just look at the dictionary keys to find out how to extract particular variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_seq', 'target', 'x_lengths'])\n"
     ]
    }
   ],
   "source": [
    "for batches in train_iterator:\n",
    "    print(batches.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the output batch has the dimensions: (batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_seq shape:  torch.Size([256, 6])\n",
      "target shape:  torch.Size([256])\n",
      "x_lengths shape:  torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for batches in train_iterator:\n",
    "    # Unpack the dictionary of batches\n",
    "    input_seq, target, x_lengths = batches['input_seq'], batches['target'], batches['x_lengths']\n",
    "    print('input_seq shape: ', input_seq.size())\n",
    "    print('target shape: ', target.size())\n",
    "    print('x_lengths shape: ', x_lengths.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_seq shape:  torch.Size([256, 31])\n",
      "target shape:  torch.Size([256])\n",
      "x_lengths shape:  torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for batches in val_iterator:\n",
    "    # Unpack the dictionary of batches\n",
    "    input_seq, target, x_lengths = batches['input_seq'], batches['target'], batches['x_lengths']\n",
    "    print('input_seq shape: ', input_seq.size())\n",
    "    print('target shape: ', target.size())\n",
    "    print('x_lengths shape: ', x_lengths.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to build the biGRU model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRU(nn.Module):\n",
    "    \"\"\"BiDirectional GRU neural network model.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    hidden_size: int\n",
    "        Number of features in the hidden state.\n",
    "    vocab_size: int\n",
    "        The size of the vocabulary.\n",
    "    embedding_dim: int\n",
    "        The size of each embedding vector.\n",
    "    output_size: int\n",
    "        Number of classes.\n",
    "    n_layers: int, optional (default=1)\n",
    "        Number of stacked recurrent layers.\n",
    "    dropout: float, optional (default=0.2)\n",
    "        Probability of an element of the tensor to be zeroed.\n",
    "    spatial_dropout: boolean, optional (default=True)\n",
    "        Whether to use the spatial dropout.\n",
    "    bidirectional: boolean, optional (default=True)\n",
    "        Whether to use the bidirectional GRU.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, vocab_size, embedding_dim, output_size, n_layers=1, dropout=0.2,\n",
    "                 spatial_dropout=True, bidirectional=True):\n",
    "        \n",
    "        # Inherit everything from the nn.Module\n",
    "        super(BiGRU, self).__init__()\n",
    "        \n",
    "        # Initialize attributes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout\n",
    "        self.spatial_dropout = spatial_dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.n_directions = 2 if self.bidirectional else 1\n",
    "        \n",
    "        # Initialize layers\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        if self.spatial_dropout:\n",
    "            self.spatial_dropout1d = nn.Dropout2d(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.hidden_size, num_layers=self.n_layers, \n",
    "                          dropout=(0 if n_layers == 1 else self.dropout_p), batch_first=True,\n",
    "                          bidirectional=self.bidirectional)\n",
    "        # Linear layer input size is equal to hidden_size * 3, becuase\n",
    "        # we will concatenate max_pooling ,avg_pooling and last hidden state\n",
    "        self.linear = nn.Linear(self.hidden_size * 3, self.output_size)\n",
    "\n",
    "        \n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        \"\"\"Forward propagate through the neural network model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_seq: torch.Tensor\n",
    "            Batch of input sequences.\n",
    "        input_lengths: torch.LongTensor\n",
    "            Batch containing sequences lengths.\n",
    "        hidden: torch.FloatTensor, optional (default=None)\n",
    "            Tensor containing initial hidden state.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Logarithm of softmaxed input tensor.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Extract batch_size\n",
    "        self.batch_size = input_seq.size(0)\n",
    "        \n",
    "        # Embeddings shapes\n",
    "        # Input: (batch_size,  seq_length)\n",
    "        # Output: (batch_size, seq_length, embedding_dim)\n",
    "        emb_out = self.embedding(input_seq)\n",
    "        \n",
    "        if self.spatial_dropout:\n",
    "            # Convert to (batch_size, embedding_dim, seq_length)\n",
    "            emb_out = emb_out.permute(0, 2, 1)\n",
    "            emb_out = self.spatial_dropout1d(emb_out)\n",
    "            # Convert back to (batch_size, seq_length, embedding_dim)\n",
    "            emb_out = emb_out.permute(0, 2, 1)\n",
    "        else:\n",
    "            emb_out = self.dropout(emb_out)\n",
    "        \n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed_emb = nn.utils.rnn.pack_padded_sequence(emb_out, input_lengths, batch_first=True)\n",
    "                \n",
    "        # GRU input/output shapes, if batch_first=True\n",
    "        # Input: (batch_size, seq_len, embedding_dim)\n",
    "        # Output: (batch_size, seq_len, hidden_size*num_directions)\n",
    "        # Number of directions = 2 when used bidirectional, otherwise 1\n",
    "        # shape of hidden: (n_layers x num_directions, batch_size, hidden_size)\n",
    "        # Hidden state defaults to zero if not provided\n",
    "        gru_out, hidden = self.gru(packed_emb, hidden)\n",
    "        # gru_out: tensor containing the output features h_t from the last layer of the GRU\n",
    "        # gru_out comprises all the hidden states in the last layer (\"last\" depth-wise, not time-wise)\n",
    "        # For biGRu gru_out is the concatenation of a forward GRU representation and a backward GRU representation\n",
    "        # hidden (h_n) comprises the hidden states after the last timestep\n",
    "        \n",
    "        # Extract and sum last hidden state\n",
    "        # Input hidden shape: (n_layers x num_directions, batch_size, hidden_size)\n",
    "        # Separate hidden state layers\n",
    "        hidden = hidden.view(self.n_layers, self.n_directions, self.batch_size, self.hidden_size)\n",
    "        last_hidden = hidden[-1]\n",
    "        # last hidden shape (num_directions, batch_size, hidden_size)\n",
    "        # Sum the last hidden state of forward and backward layer\n",
    "        last_hidden = torch.sum(last_hidden, dim=0)\n",
    "        # Summed last hidden shape (batch_size, hidden_size)\n",
    "        \n",
    "        # Pad a packed batch\n",
    "        # gru_out output shape: (batch_size, seq_len, hidden_size*num_directions)\n",
    "        gru_out, lengths = nn.utils.rnn.pad_packed_sequence(gru_out, batch_first=True)\n",
    "              \n",
    "        # Sum the gru_out along the num_directions\n",
    "        if self.bidirectional:\n",
    "            gru_out = gru_out[:,:,:self.hidden_size] + gru_out[:,:,self.hidden_size:]\n",
    "        \n",
    "        # Select the maximum value over each dimension of the hidden representation (max pooling)\n",
    "        # Permute the input tensor to dimensions: (batch_size, hidden, seq_len)\n",
    "        # Output dimensions: (batch_size, hidden_size)\n",
    "        max_pool = F.adaptive_max_pool1d(gru_out.permute(0,2,1), (1,)).view(self.batch_size,-1)\n",
    "        \n",
    "        # Consider the average of the representations (mean pooling)\n",
    "        # Sum along the batch axis and divide by the corresponding lengths (FloatTensor)\n",
    "        # Output shape: (batch_size, hidden_size)\n",
    "        avg_pool = torch.sum(gru_out, dim=1) / lengths.view(-1,1).type(torch.FloatTensor) \n",
    "\n",
    "        # Concatenate max_pooling, avg_pooling and last hidden state tensors\n",
    "        concat_out = torch.cat([last_hidden, max_pool, avg_pool], dim=1)\n",
    "\n",
    "        #concat_out = self.dropout(concat_out)\n",
    "        out = self.linear(concat_out)\n",
    "        return F.log_softmax(out, dim=-1)\n",
    "    \n",
    "    \n",
    "    def add_loss_fn(self, loss_fn):\n",
    "        \"\"\"Add loss function to the model.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "\n",
    "    def add_optimizer(self, optimizer):\n",
    "        \"\"\"Add optimizer to the model.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        \n",
    "    def add_device(self, device=torch.device('cpu')):\n",
    "        \"\"\"Specify the device.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "    \n",
    "    \n",
    "    def train_model(self, train_iterator):\n",
    "        \"\"\"Perform single training epoch.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        train_iterator: BatchIterator\n",
    "            BatchIterator class object containing training batches.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        train_losses: list\n",
    "            List of the training average batch losses.\n",
    "        avg_loss: float\n",
    "            Average loss on the entire training set.\n",
    "        accuracy: float\n",
    "            Models accuracy on the entire training set.\n",
    "            \n",
    "        \"\"\"\n",
    "        self.train()\n",
    "        \n",
    "        train_losses = []\n",
    "        losses = []\n",
    "        losses_list = []\n",
    "        num_seq = 0\n",
    "        batch_correct = 0\n",
    "            \n",
    "        for i, batches in tqdm_notebook(enumerate(train_iterator, 1), total=len(train_iterator), desc='Training'):\n",
    "            input_seq, target, x_lengths = batches['input_seq'], batches['target'], batches['x_lengths']\n",
    "            \n",
    "            input_seq.to(self.device)\n",
    "            target.to(self.device)\n",
    "            x_lengths.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            pred = self.forward(input_seq, x_lengths)\n",
    "            loss = self.loss_fn(pred, target)\n",
    "            loss.backward()\n",
    "            losses.append(loss.data.cpu().numpy())\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            losses_list.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            pred = torch.argmax(pred, 1)\n",
    "\n",
    "            if self.device.type == 'cpu':\n",
    "                batch_correct += (pred.cpu() == target.cpu()).sum().item()\n",
    "\n",
    "            else:\n",
    "                batch_correct += (pred == target).sum().item()\n",
    "\n",
    "            num_seq += len(input_seq)     \n",
    "    \n",
    "            if i % 100 == 0:\n",
    "                avg_train_loss = np.mean(losses)\n",
    "                train_losses.append(avg_train_loss)\n",
    "                \n",
    "                accuracy = batch_correct / num_seq\n",
    "                \n",
    "                print('Iteration: {}. Average training loss: {:.4f}. Accuracy: {:.3f}'\\\n",
    "                      .format(i, avg_train_loss, accuracy))\n",
    "                \n",
    "                losses = []\n",
    "                \n",
    "            avg_loss = np.mean(losses_list)\n",
    "            accuracy = batch_correct / num_seq\n",
    "                              \n",
    "        return train_losses, avg_loss, accuracy\n",
    "    \n",
    "    \n",
    "    def evaluate_model(self, eval_iterator, conf_mtx=False):\n",
    "        \"\"\"Perform the one evaluation epoch.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        eval_iterator: BatchIterator\n",
    "            BatchIterator class object containing evaluation batches.\n",
    "        conf_mtx: boolean, optional (default=False)\n",
    "            Whether to print the confusion matrix at each epoch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        eval_losses: list\n",
    "            List of the evaluation average batch losses.\n",
    "        avg_loss: float\n",
    "            Average loss on the entire evaluation set.\n",
    "        accuracy: float\n",
    "            Models accuracy on the entire evaluation set.\n",
    "        conf_matrix: list\n",
    "            Confusion matrix.\n",
    "            \n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        eval_losses = []\n",
    "        losses = []\n",
    "        losses_list = []\n",
    "        num_seq = 0\n",
    "        batch_correct = 0\n",
    "        pred_total = torch.LongTensor()\n",
    "        target_total = torch.LongTensor()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, batches in tqdm_notebook(enumerate(eval_iterator, 1), total=len(eval_iterator), desc='Evaluation'):\n",
    "                input_seq, target, x_lengths = batches['input_seq'], batches['target'], batches['x_lengths']\n",
    "                \n",
    "                input_seq.to(self.device)\n",
    "                target.to(self.device)\n",
    "                x_lengths.to(self.device)\n",
    "\n",
    "                pred = self.forward(input_seq, x_lengths)\n",
    "                loss = self.loss_fn(pred, target)\n",
    "                losses.append(loss.data.cpu().numpy())\n",
    "                losses_list.append(loss.data.cpu().numpy())\n",
    "                \n",
    "                pred = torch.argmax(pred, 1)\n",
    "                                \n",
    "                if self.device.type == 'cpu':\n",
    "                    batch_correct += (pred.cpu() == target.cpu()).sum().item()\n",
    "                    \n",
    "                else:\n",
    "                    batch_correct += (pred == target).sum().item()\n",
    "                    \n",
    "                num_seq += len(input_seq)     \n",
    "                \n",
    "                pred_total = torch.cat([pred_total, pred], dim=0)\n",
    "                target_total = torch.cat([target_total, target], dim=0)\n",
    "                \n",
    "                if i % 100 == 0:\n",
    "                    avg_batch_eval_loss = np.mean(losses)\n",
    "                    eval_losses.append(avg_batch_eval_loss)\n",
    "                    \n",
    "                    accuracy = batch_correct / num_seq\n",
    "                    \n",
    "                    print('Iteration: {}. Average evaluation loss: {:.4f}. Accuracy: {:.2f}'\\\n",
    "                          .format(i, avg_batch_eval_loss, accuracy))\n",
    "\n",
    "                    losses = []\n",
    "                    \n",
    "            avg_loss_list = []\n",
    "                    \n",
    "            avg_loss = np.mean(losses_list)\n",
    "            accuracy = batch_correct / num_seq\n",
    "            \n",
    "            conf_matrix = confusion_matrix(target_total.view(-1), pred_total.view(-1))\n",
    "        \n",
    "        if conf_mtx:\n",
    "            print('\\tConfusion matrix: ', conf_matrix)\n",
    "            \n",
    "        return eval_losses, avg_loss, accuracy, conf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will instantiate the model, add loss function, optimizer, and device to it and begin the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start epoch [1/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9e3b03f38242d986be18897f69b21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a539d4eabd4713a5fb7e20a549b6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/20]: Train accuracy: 0.677. Train loss: 0.6172. Evaluation accuracy: 0.757. Evaluation loss: 0.5549\n",
      "\n",
      "Start epoch [2/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4bbde2cd814e9ba609ddb09534f3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df3c70525304166823062b2c80f91d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/20]: Train accuracy: 0.747. Train loss: 0.5652. Evaluation accuracy: 0.757. Evaluation loss: 0.5431\n",
      "\n",
      "Start epoch [3/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d8d23cc26849c597554f5693334ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed28e5e0fad54773bba3b588976dffcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/20]: Train accuracy: 0.747. Train loss: 0.5577. Evaluation accuracy: 0.757. Evaluation loss: 0.5304\n",
      "\n",
      "Start epoch [4/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b3db7ee2774171bfdfebde31c48d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f44dfc31004786a582f5722fa50d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/20]: Train accuracy: 0.747. Train loss: 0.5496. Evaluation accuracy: 0.759. Evaluation loss: 0.5149\n",
      "\n",
      "Start epoch [5/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291c2874838745f7bed0981a0c02c27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbd4048e32e4e5db37be3d41e93d87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/20]: Train accuracy: 0.748. Train loss: 0.5375. Evaluation accuracy: 0.761. Evaluation loss: 0.4975\n",
      "\n",
      "Start epoch [6/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e3a05857ec4968ba630051ea52772e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9276ad2c5aac402b8cf0dc789150362d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/20]: Train accuracy: 0.752. Train loss: 0.5246. Evaluation accuracy: 0.770. Evaluation loss: 0.4812\n",
      "\n",
      "Start epoch [7/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b409d48e3e8941f49a3281a0fbab51b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fee2b19bc24ed2b7c42e2c41b11617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/20]: Train accuracy: 0.758. Train loss: 0.5114. Evaluation accuracy: 0.776. Evaluation loss: 0.4685\n",
      "\n",
      "Start epoch [8/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4023072df9b54106b04c1779d552744e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be22d3e7e4c3405da12f9287cdd1ef8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/20]: Train accuracy: 0.768. Train loss: 0.4945. Evaluation accuracy: 0.785. Evaluation loss: 0.4586\n",
      "\n",
      "Start epoch [9/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec805a7690941e5834ec1e30e47ed80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125b22cd421744138933c1042b2be5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/20]: Train accuracy: 0.774. Train loss: 0.4810. Evaluation accuracy: 0.795. Evaluation loss: 0.4504\n",
      "\n",
      "Start epoch [10/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ea04f9b8f24942bc93151f183dff28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5941c69396445fbe532fc4c61d1fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/20]: Train accuracy: 0.785. Train loss: 0.4657. Evaluation accuracy: 0.800. Evaluation loss: 0.4441\n",
      "\n",
      "Start epoch [11/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e95195f0a534ff08cd31bee4dd974af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e02f959e17489595befcc3383983e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [11/20]: Train accuracy: 0.786. Train loss: 0.4577. Evaluation accuracy: 0.805. Evaluation loss: 0.4397\n",
      "\n",
      "Start epoch [12/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2436240ce542e6bef7d0eb6b4a0350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aee556f105d48b087a769674ddf6c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [12/20]: Train accuracy: 0.794. Train loss: 0.4457. Evaluation accuracy: 0.809. Evaluation loss: 0.4347\n",
      "\n",
      "Start epoch [13/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c538c99a805a407889d5d8d68b6d96f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a1e851d2ee4bbbbe3cd0e94f75b78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [13/20]: Train accuracy: 0.803. Train loss: 0.4345. Evaluation accuracy: 0.814. Evaluation loss: 0.4323\n",
      "\n",
      "Start epoch [14/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cef1c8b7c94a098eff2fd4b5592617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4550e766c8f94ac0b5cb35f7352ffba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [14/20]: Train accuracy: 0.808. Train loss: 0.4252. Evaluation accuracy: 0.815. Evaluation loss: 0.4310\n",
      "\n",
      "Start epoch [15/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9acebab5d604cb8bad50083410d27ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740b705e43f84315ac760befbf9d7c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [15/20]: Train accuracy: 0.813. Train loss: 0.4141. Evaluation accuracy: 0.813. Evaluation loss: 0.4300\n",
      "\n",
      "Start epoch [16/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf015aacc9341a7bf6af1149e39dc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a9a607371a4b39b0ff4fde7d6a306c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [16/20]: Train accuracy: 0.816. Train loss: 0.4094. Evaluation accuracy: 0.816. Evaluation loss: 0.4283\n",
      "\n",
      "Start epoch [17/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f51578f5aae478186a780cde8eebf11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614dd45f42f24df88d44490ae4706799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [17/20]: Train accuracy: 0.822. Train loss: 0.3956. Evaluation accuracy: 0.816. Evaluation loss: 0.4289\n",
      "\n",
      "Start epoch [18/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceec5940fb5c4a329a1f90847e59fd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232efff8b59a4684898bbd3b1611f8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [18/20]: Train accuracy: 0.824. Train loss: 0.3966. Evaluation accuracy: 0.815. Evaluation loss: 0.4284\n",
      "\n",
      "Start epoch [19/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3d94b20d8e4cab95f3d7d053f6bb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0011b8f9e04db0b116106b9a9620c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [19/20]: Train accuracy: 0.830. Train loss: 0.3844. Evaluation accuracy: 0.816. Evaluation loss: 0.4285\n",
      "\n",
      "Start epoch [20/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eeecd718cbd42628f9d8edab5d57484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4873d5225704eac85197c11a572452c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [20/20]: Train accuracy: 0.831. Train loss: 0.3841. Evaluation accuracy: 0.815. Evaluation loss: 0.4274\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "hidden_size = 8\n",
    "vocab_size = len(train_iterator.word2index)\n",
    "embedding_dim = 200\n",
    "output_size = 2\n",
    "n_layers = 1\n",
    "dropout = 0.5\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "spatial_dropout = True\n",
    "\n",
    "# Check whether system supports CUDA\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "model = BiGRU(hidden_size, vocab_size, embedding_dim, output_size, n_layers, dropout,\n",
    "              spatial_dropout, bidirectional=True)\n",
    "\n",
    "# Move the model to GPU if possible\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "model.add_loss_fn(nn.NLLLoss())\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.add_optimizer(optimizer)\n",
    "\n",
    "device = torch.device('cuda' if CUDA else 'cpu')\n",
    "\n",
    "model.add_device(device)\n",
    "\n",
    "# Instantiate the EarlyStopping\n",
    "early_stop = EarlyStopping(wait_epochs=1)\n",
    "\n",
    "train_losses_list, train_avg_loss_list, train_accuracy_list = [], [], []\n",
    "eval_avg_loss_list, eval_accuracy_list, conf_matrix_list = [], [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print('\\nStart epoch [{}/{}]'.format(epoch+1, epochs))\n",
    "    \n",
    "    train_losses, train_avg_loss, train_accuracy = model.train_model(train_iterator)\n",
    "    \n",
    "    train_losses_list.append(train_losses)\n",
    "    train_avg_loss_list.append(train_avg_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    \n",
    "    _, eval_avg_loss, eval_accuracy, conf_matrix = model.evaluate_model(val_iterator)\n",
    "    \n",
    "    eval_avg_loss_list.append(eval_avg_loss)\n",
    "    eval_accuracy_list.append(eval_accuracy)\n",
    "    conf_matrix_list.append(conf_matrix)\n",
    "    \n",
    "    print('\\nEpoch [{}/{}]: Train accuracy: {:.3f}. Train loss: {:.4f}. Evaluation accuracy: {:.3f}. Evaluation loss: {:.4f}'\\\n",
    "          .format(epoch+1, epochs, train_accuracy, train_avg_loss, eval_accuracy, eval_avg_loss))\n",
    "    \n",
    "    if early_stop.stop(eval_avg_loss, model, delta=0.003):\n",
    "        break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6f9d95734c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add the dataset initial loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_avg_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0meval_avg_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Add the dataset initial loss\n",
    "train_avg_loss_list.insert(0, train_losses_list[0][0])\n",
    "eval_avg_loss_list.insert(0, train_losses_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and the validation learning curve\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_avg_loss_list, label='Training loss')\n",
    "plt.plot(eval_avg_loss_list, label='Evaluation loss')\n",
    "plt.xlabel('Epoch', size=12)\n",
    "plt.ylabel('Loss', size=12)\n",
    "plt.title('biGRU model learning curves')\n",
    "plt.xticks(ticks=range(21))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(6,6))\n",
    "ax = sns.heatmap(conf_matrix, fmt='d', annot=True, linewidths=1, square=True)\n",
    "ax.set_xlabel('Predictions', size=12)\n",
    "ax.set_ylabel('True labels', size=12) \n",
    "ax.set_title('Confusion Matrix', size=12); \n",
    "ax.xaxis.set_ticklabels(['True', 'False'])\n",
    "ax.yaxis.set_ticklabels(['True', 'False'])\n",
    "ax.set_ylim(2,0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieved the validation accuracy of 0.878, while the training accuracy was 0.908. The model's best state was saved to the *checkpoint.pt* file in the current directory. The training wasn't stopped by EarlyStopping object because the validation loss changes were too small and fluctuated near the same value.\n",
    "\n",
    "The training process that is presented above regards the model with the tuned hyperparameters. The steps we went through when doing hyperparameters fine-tuning are listed in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters fine-tuning\n",
    "\n",
    "After the model is created we have to tune its hyperparameters like hidden_size, embedding_dim, n_layers, dropout, spatial_dropout, learning_rate, batch_size, seq_length or min_word_count and then chose the set of parameters that enable the model to achieve the best performance (a model that returns the highest accuracy or lowest loss) on the validation set.\n",
    "\n",
    "Below we will show how the training and validation losses change during the training, do to so we have to disable the early stopping. We are interested in comparing training and validations losses in terms of their values but also in the directions in which they are heading during the training. This will help us discern the overfitting if it occurs.\n",
    "\n",
    "The initial parameters used in our model are the following:\n",
    "- hidden_size = 100\n",
    "- embedding_dim = 200\n",
    "- n_layers = 1\n",
    "- dropout = 0.2\n",
    "- learning_rate = 0.001\n",
    "- batch_size = 32\n",
    "- spatial_dropout = False\n",
    "- min_word_count = 5\n",
    "- max_seq_len = 0.8\n",
    "\n",
    "Then we will change one of the above hyperparameters, train the model and depict the training and validation loss at each epoch during the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Learning curves for the model with dropout  set to 0.2.\n",
    "\n",
    "dropout = 0.2\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_droput02.png\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "With the lowest evaluation loss (at second epoch), the model archived evaluation accuracy of 0.861 while the training accuracy at that time was 0.883.\n",
    "\n",
    "We can notice on the preceding plot, that the training loss constantly decrease together with the validation loss, but at the second epoch, the validation loss reverse and begin to increase. This behaviour indicates that our model is overfitted, it learns too well how to map training input variables to the target, thus it cannot generalize its performance on some unseen data (validation set). One of the solutions to this problem is to increase the dropout probability, so the neural network will be forced to learn some more robust correlations in the data since the neurons will not depend anymore on each other, therefore the overfitting will be reduced.  The best remedy to the overfitting issue would be to gain more training examples, but our data set is finite, so we are not able to do that.."
   ]
  },
  {
   "attachments": {
    "learning_curves_droput05.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Learning curves for the model with dropout set to 0.5.\n",
    "\n",
    "dropout = 0.5\n",
    "\n",
    "![assets/learning_curves_droput05.png](attachment:learning_curves_droput05.png)\n",
    "\n",
    "With dropout probability set to 0.5 the validation loss decrease longer than in the first case and reverses at 5th epoch (at the value of loss a bit greater than with dropout = 0.2). This denotes that the overfitting problem still occurs in our model. The validation accuracy is comparable to the previous model.\n",
    "\n",
    "In the next training procedure, we will use the spatial dropout instead of the traditional dropout after the embedding layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Learning curves for the model with spatial dropout set to 0.5.\n",
    "\n",
    "dropout = 0.5 <br>\n",
    "spatial_dropout = True\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_spatial_droput.png\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "When we use the spatial dropout instead of normal dropout the evaluation loss decrease to the value around 0.36, similar to the first example where we used dropout = 0.2, but lower than with the dropout probability set to 0.5. With spatial dropout, the loss begin to reverse at the second epoch, but it increases much slower than in the previous cases (the gap between training loss and validation loss is smaller). As a summary, we can say that considering all regularization methods results, the spatial dropout provides the model best behaviour.\n",
    "\n",
    "The next hyperparameter that we are going to tune is the hidden_size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Learning curves for the model with hidden_size = 64.\n",
    "\n",
    "There are many rules regarding the choice of the hidden size. For instance, we can use the following formula to calculate the number of hidden units $N_{h}$ [https://ai.stackexchange.com/questions/3156/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm]:\n",
    "<br>\n",
    "\n",
    "<p><center>$N_{h} = \\frac{N_{s}}{(\\alpha \\cdot (N_{i} + N_{0}))}$</center></p>\n",
    "\n",
    "Where: <br>\n",
    "$N_{s}$ - number of samples in training data set. <br>\n",
    "$\\alpha$ - an arbitrary scaling factor usually 2-10.<br>\n",
    "$N_{i}$ - number of input neurons.<br>\n",
    "$N_{0}$ - number of output neurons.<br>\n",
    "\n",
    "Nevertheless in most cases, the number of hidden units have to be figured out by series of trials.\n",
    "\n",
    "dropout = 0.5 <br>\n",
    "spatial_dropout = True <br>\n",
    "hidden_size = 64 <br>\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_hidden64.png\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "As we can see reducing the number of hidden units makes the validation loss curve more flat after the first epoch than it was in the preceding examples.\n",
    "\n",
    "We will go further and decrease the hidden_size to 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Learning curves for the model with hidden_size = 32.\n",
    "\n",
    "dropout = 0.5 <br>\n",
    "spatial_dropout = True <br>\n",
    "hidden_size = 32 <br>\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_hidden32.png\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "After decreasing the hidden_size to 32, the validation loss became even more flat and at the 3rd epoch, it begins to fluctuate around the value of 0.38. We can see that decreasing the number of hidden units helped and learning curves starting to look as expected, so we will diminish the hidden_size one more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Learning curves for the model with hidden_size = 16.\n",
    "\n",
    "dropout = 0.5 <br>\n",
    "spatial_dropout = True <br>\n",
    "hidden_size = 16 <br>\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_hidden16.png\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "This time the validation learning curve takes a bit lower values and it is more smooth than the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Learning curves for the model with hidden_size = 8.\n",
    "\n",
    "dropout = 0.5 <br>\n",
    "spatial_dropout = True <br>\n",
    "hidden_size = 8 <br>\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_hidden8.png\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "The validation loss slowly, but constantly decreases during the training, so we can say that overfitting has been overcame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Learning curves for the model with n_layers = 2.\n",
    "\n",
    "dropout = 0.5 <br>\n",
    "spatial_dropout = True <br>\n",
    "hidden_size = 8 <br>\n",
    "n_layers = 2 <br>\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_nlayers2.png\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "Using one addtional GRU layer didn't make a difference for our model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Learning curves for the model with batch_size = 16.\n",
    "\n",
    "Now we are going to change the batch_size to 16, as reducing batch size might work as regularizer since losses calculated on small batches are noisier, thus model has a lower tendentious to overfitting. The drawback of this method is the processing time, which increases while batch size decreases. Notice that we will change back the n_layers to 1.\n",
    "\n",
    "dropout = 0.5 <br>\n",
    "spatial_dropout = True <br>\n",
    "hidden_size = 8 <br>\n",
    "n_layers = 1 <br>\n",
    "batch_size = 16 <br>\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_batch16.png\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "Reducing the batch_size cause that the validation loss diminished to the value around 0.33 (among to the lowest of all our trials), but then the loss began to increase. That might be only some local peak, or the model started to overfit to the training dataset.\n",
    "\n",
    "The validation loss curve tends to be under the training curve for most of the time. The explanation of why it behaves like that is the following:\n",
    "- The validation error is smaller than the training error because the dropout is active during the training, while during the evaluation, dropout layer is inactive, thus we got more smooth results in the second case.  \n",
    "- The training loss is measured as the mean loss on the entire training set, and since the performance improves during the training, the general training loss depicted on the plot is worse than the lowest loss calculated at the end of the set. While the validation loss is calculated using the model's last state, which is associated with the best performance at the given time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Learning curves for the model with batch_size = 64.\n",
    "\n",
    "Increasing the batch_size will speed up the training process.\n",
    "<br>\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_batch64.png\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "As we can see, we gained positive results by using larger batch_size, namely, the learning process was much faster and the validation loss is comparable to the previous results, it doesn't even raise at the end of the training."
   ]
  },
  {
   "attachments": {
    "learning_curves_batch128.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Learning curves for the model with batch_size = 128.\n",
    "\n",
    "![assets/learning_curves_batch128.png](attachment:learning_curves_batch128.png)\n",
    "\n",
    "This time we can see the improvement, the validation error seems to constantly decrease, the curve is more smooth. As it turned out this could be the right way to one more time improve the model's predictive abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Learning curves for the model with batch_size = 256.\n",
    "<br>\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_batch256.png\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "During the above training trial, we recorded the lowest validation error among all preceding trials that equals around 0.32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Learning curves for the model with min_word_count = 3 and max_seq_len = 0.9.\n",
    "\n",
    "As the last hyperparameters to tune we will use the min_word_count and max_seq_len.\n",
    "\n",
    "* min_word_count will be changed to the value of 3 so that the vocabulary will contain all the words which occur at least 3 times in the entire dataset.\n",
    "* max_seq_len is going to be changed to the values of 0.9, which corresponds to the 0.9 quantile of the distribution of the lengths, that will be the maximum lengths threshold.\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/learning_curves_mwc3_msl09.png\" width=\"500\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The summary - final set of hyperparameters\n",
    "\n",
    "Considering all above training trials, we can draw the following conclusions:\n",
    "- increasing the dropout probability helps in reducing the model's overfitting.\n",
    "- spatial dropout works better in terms of decreasing the variance problem than the traditional dropout.\n",
    "- the most improvement in reducing overfitting is due to the reduction of hidden_size.\n",
    "- using stacked GRU doesn't improve in our case the model's performance.\n",
    "- reducing the batch_size doesn't significantly affect the model's learning ability what is rather unexpected while increasing the batch_size does improve a bit the model's performance.\n",
    "\n",
    "The following are the hyperparameters that will be used to finaly train our neural network:\n",
    "- hidden_size = 8 <br>\n",
    "- embedding_dim = 200 <br>\n",
    "- n_layers = 1 <br>\n",
    "- dropout = 0.5 <br>\n",
    "- learning_rate = 0.001 <br>\n",
    "- epochs = 20 <br>\n",
    "- spatial_dropout = True <br>\n",
    "- batch_size = 256 <br>\n",
    "- min_word_count = 3 <br>\n",
    "- max_seq_len = 0.9 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will use the *tensorboardX* to create the graph of our neural network model that has been depicted at the top of this notebook. You can encounter torch._C.Value issue while using *add.graph()* method, to tackle that I recommend following the *github* thread devoted to this topic:\n",
    "<br>https://github.com/lanpa/tensorboardX/issues/483<br>\n",
    "namely, you can try to build tensorboardX from source with:\n",
    "<br>*git clone https://github.com/lanpa/tensorboardX && cd tensorboardX && python setup.py install*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self : ClassType<BiGRU>,\n",
      "      %input_seq : Long(256, 35),\n",
      "      %lengths.1 : Long(256)):\n",
      "  %1 : ClassType<Embedding> = prim::GetAttr[name=\"embedding\"](%self)\n",
      "  %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%1)\n",
      "  %5 : ClassType<GRU> = prim::GetAttr[name=\"gru\"](%self)\n",
      "  %6 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%5)\n",
      "  %7 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%5)\n",
      "  %8 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%5)\n",
      "  %9 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%5)\n",
      "  %10 : Tensor = prim::GetAttr[name=\"weight_ih_l0_reverse\"](%5)\n",
      "  %11 : Tensor = prim::GetAttr[name=\"weight_hh_l0_reverse\"](%5)\n",
      "  %12 : Tensor = prim::GetAttr[name=\"bias_ih_l0_reverse\"](%5)\n",
      "  %13 : Tensor = prim::GetAttr[name=\"bias_hh_l0_reverse\"](%5)\n",
      "  %14 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%5)\n",
      "  %15 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%5)\n",
      "  %16 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%5)\n",
      "  %17 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%5)\n",
      "  %18 : Tensor = prim::GetAttr[name=\"weight_ih_l1_reverse\"](%5)\n",
      "  %19 : Tensor = prim::GetAttr[name=\"weight_hh_l1_reverse\"](%5)\n",
      "  %20 : Tensor = prim::GetAttr[name=\"bias_ih_l1_reverse\"](%5)\n",
      "  %21 : Tensor = prim::GetAttr[name=\"bias_hh_l1_reverse\"](%5)\n",
      "  %22 : ClassType<Linear> = prim::GetAttr[name=\"linear\"](%self)\n",
      "  %weight : Tensor = prim::GetAttr[name=\"weight\"](%22)\n",
      "  %bias : Tensor = prim::GetAttr[name=\"bias\"](%22)\n",
      "  %27 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:74:0\n",
      "  %28 : int = aten::size(%input_seq, %27), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:74:0\n",
      "  %29 : Long() = prim::NumToTensor(%28), scope: BiGRU\n",
      "  %161 : int = aten::Int(%29), scope: BiGRU\n",
      "  %98 : int = aten::Int(%29), scope: BiGRU\n",
      "  %30 : int = prim::Constant[value=-1](), scope: BiGRU/Embedding[embedding] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:1467:0\n",
      "  %31 : bool = prim::Constant[value=0](), scope: BiGRU/Embedding[embedding] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:1467:0\n",
      "  %32 : bool = prim::Constant[value=0](), scope: BiGRU/Embedding[embedding] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:1467:0\n",
      "  %emb_out.1 : Float(256, 35, 200) = aten::embedding(%weight.1, %input_seq, %30, %31, %32), scope: BiGRU/Embedding[embedding] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:1467:0\n",
      "  %34 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:83:0\n",
      "  %35 : int = prim::Constant[value=2](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:83:0\n",
      "  %36 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:83:0\n",
      "  %37 : int[] = prim::ListConstruct(%34, %35, %36), scope: BiGRU\n",
      "  %input.1 : Float(256!, 200!, 35!) = aten::permute(%emb_out.1, %37), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:83:0\n",
      "  %39 : float = prim::Constant[value=0.5](), scope: BiGRU/Dropout2d[spatial_dropout1d] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:844:0\n",
      "  %40 : bool = prim::Constant[value=0](), scope: BiGRU/Dropout2d[spatial_dropout1d] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:844:0\n",
      "  %emb_out : Float(256!, 200!, 35!) = aten::feature_dropout(%input.1, %39, %40), scope: BiGRU/Dropout2d[spatial_dropout1d] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:844:0\n",
      "  %42 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:86:0\n",
      "  %43 : int = prim::Constant[value=2](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:86:0\n",
      "  %44 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:86:0\n",
      "  %45 : int[] = prim::ListConstruct(%42, %43, %44), scope: BiGRU\n",
      "  %input.2 : Float(256, 35, 200) = aten::permute(%emb_out, %45), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:86:0\n",
      "  %47 : Device = prim::Constant[value=\"cpu\"](), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:265:0\n",
      "  %48 : int = prim::Constant[value=4](), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:265:0\n",
      "  %49 : bool = prim::Constant[value=0](), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:265:0\n",
      "  %50 : bool = prim::Constant[value=0](), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:265:0\n",
      "  %lengths.2 : Long(256) = aten::to(%lengths.1, %47, %48, %49, %50), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:265:0\n",
      "  %52 : bool = prim::Constant[value=1](), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:275:0\n",
      "  %input.3 : Float(8804, 200), %batch_sizes : Long(35) = aten::_pack_padded_sequence(%input.2, %lengths.2, %52), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:275:0\n",
      "  %58 : int = prim::Constant[value=4](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:691:0\n",
      "  %59 : int = prim::Constant[value=256](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:691:0\n",
      "  %60 : int = prim::Constant[value=4](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:691:0\n",
      "  %61 : int[] = prim::ListConstruct(%58, %59, %60), scope: BiGRU/GRU[gru]\n",
      "  %62 : int = prim::Constant[value=6](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:691:0\n",
      "  %63 : int = prim::Constant[value=0](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:691:0\n",
      "  %64 : Device = prim::Constant[value=\"cpu\"](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:691:0\n",
      "  %65 : bool = prim::Constant[value=0](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:691:0\n",
      "  %hx : Float(4, 256, 4) = aten::zeros(%61, %62, %63, %64, %65), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:691:0\n",
      "  %90 : Tensor[] = prim::ListConstruct(%6, %7, %8, %9, %10, %11, %12, %13, %14, %15, %16, %17, %18, %19, %20, %21), scope: BiGRU/GRU[gru]\n",
      "  %91 : bool = prim::Constant[value=1](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:682:0\n",
      "  %92 : int = prim::Constant[value=2](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:682:0\n",
      "  %93 : float = prim::Constant[value=0.5](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:682:0\n",
      "  %94 : bool = prim::Constant[value=0](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:682:0\n",
      "  %95 : bool = prim::Constant[value=1](), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:682:0\n",
      "  %96 : Float(8804, 8), %hidden.1 : Float(4, 256, 4) = aten::gru(%input.3, %batch_sizes, %hx, %90, %91, %92, %93, %94, %95), scope: BiGRU/GRU[gru] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py:682:0\n",
      "  %99 : int = prim::Constant[value=2](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:108:0\n",
      "  %100 : int = prim::Constant[value=2](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:108:0\n",
      "  %101 : int = prim::Constant[value=4](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:108:0\n",
      "  %102 : int[] = prim::ListConstruct(%99, %100, %98, %101), scope: BiGRU\n",
      "  %hidden : Float(2, 2, 256, 4) = aten::view(%hidden.1, %102), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:108:0\n",
      "  %104 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:109:0\n",
      "  %105 : int = prim::Constant[value=-1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:109:0\n",
      "  %last_hidden.1 : Float(2, 256, 4) = aten::select(%hidden, %104, %105), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:109:0\n",
      "  %107 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:112:0\n",
      "  %108 : int[] = prim::ListConstruct(%107), scope: BiGRU\n",
      "  %109 : bool = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:112:0\n",
      "  %110 : int? = prim::Constant(), scope: BiGRU\n",
      "  %last_hidden : Float(256, 4) = aten::sum(%last_hidden.1, %108, %109, %110), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:112:0\n",
      "  %112 : int = prim::Constant[value=0](), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:313:0\n",
      "  %113 : int = aten::size(%batch_sizes, %112), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:313:0\n",
      "  %max_seq_length : Long() = prim::NumToTensor(%113), scope: BiGRU\n",
      "  %115 : int = aten::Int(%max_seq_length), scope: BiGRU\n",
      "  %116 : bool = prim::Constant[value=1](), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:322:0\n",
      "  %117 : float = prim::Constant[value=0](), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:322:0\n",
      "  %gru_out.1 : Float(256!, 35!, 8), %lengths : Long(256) = aten::_pad_packed_sequence(%96, %batch_sizes, %116, %117, %115), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/utils/rnn.py:322:0\n",
      "  %120 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %121 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %122 : int = prim::Constant[value=9223372036854775807](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %123 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %124 : Float(256!, 35!, 8) = aten::slice(%gru_out.1, %120, %121, %122, %123), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %125 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %126 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %127 : int = prim::Constant[value=9223372036854775807](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %128 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %129 : Float(256!, 35!, 8) = aten::slice(%124, %125, %126, %127, %128), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %130 : int = prim::Constant[value=2](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %131 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %132 : int = prim::Constant[value=4](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %133 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %134 : Float(256!, 35!, 4) = aten::slice(%129, %130, %131, %132, %133), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %135 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %136 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %137 : int = prim::Constant[value=9223372036854775807](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %138 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %139 : Float(256!, 35!, 8) = aten::slice(%gru_out.1, %135, %136, %137, %138), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %140 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %141 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %142 : int = prim::Constant[value=9223372036854775807](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %143 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %144 : Float(256!, 35!, 8) = aten::slice(%139, %140, %141, %142, %143), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %145 : int = prim::Constant[value=2](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %146 : int = prim::Constant[value=4](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %147 : int = prim::Constant[value=9223372036854775807](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %148 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %149 : Float(256!, 35!, 4) = aten::slice(%144, %145, %146, %147, %148), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %150 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %gru_out : Float(256!, 35!, 4) = aten::add(%134, %149, %150), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:121:0\n",
      "  %152 : int = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:126:0\n",
      "  %153 : int = prim::Constant[value=2](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:126:0\n",
      "  %154 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:126:0\n",
      "  %155 : int[] = prim::ListConstruct(%152, %153, %154), scope: BiGRU\n",
      "  %input.4 : Float(256, 4!, 35!) = aten::permute(%gru_out, %155), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:126:0\n",
      "  %157 : int = prim::Constant[value=1](), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:664:0\n",
      "  %158 : int[] = prim::ListConstruct(%157), scope: BiGRU\n",
      "  %159 : Float(256, 4, 1), %160 : Long(256, 4, 1) = aten::adaptive_max_pool1d(%input.4, %158), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:664:0\n",
      "  %162 : int = prim::Constant[value=-1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:126:0\n",
      "  %163 : int[] = prim::ListConstruct(%161, %162), scope: BiGRU\n",
      "  %max_pool : Float(256, 4) = aten::view(%159, %163), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:126:0\n",
      "  %165 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %166 : int[] = prim::ListConstruct(%165), scope: BiGRU\n",
      "  %167 : bool = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %168 : int? = prim::Constant(), scope: BiGRU\n",
      "  %169 : Float(256, 4) = aten::sum(%gru_out, %166, %167, %168), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %170 : int = prim::Constant[value=-1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %171 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %172 : int[] = prim::ListConstruct(%170, %171), scope: BiGRU\n",
      "  %173 : Long(256, 1) = aten::view(%lengths, %172), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %174 : Device = prim::Constant[value=\"cpu\"](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %175 : int = prim::Constant[value=6](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %176 : bool = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %177 : bool = prim::Constant[value=0](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %178 : Float(256, 1) = aten::to(%173, %174, %175, %176, %177), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %avg_pool : Float(256, 4) = aten::div(%169, %178), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:131:0\n",
      "  %180 : Tensor[] = prim::ListConstruct(%last_hidden, %max_pool, %avg_pool), scope: BiGRU\n",
      "  %181 : int = prim::Constant[value=1](), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:134:0\n",
      "  %input.5 : Float(256, 12) = aten::cat(%180, %181), scope: BiGRU # <ipython-input-24-5f3ae3dfaec2>:134:0\n",
      "  %183 : Float(12!, 2!) = aten::t(%weight), scope: BiGRU/Linear[linear] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:1369:0\n",
      "  %184 : int = prim::Constant[value=1](), scope: BiGRU/Linear[linear] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:1369:0\n",
      "  %185 : int = prim::Constant[value=1](), scope: BiGRU/Linear[linear] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:1369:0\n",
      "  %input : Float(256, 2) = aten::addmm(%bias, %input.5, %183, %184, %185), scope: BiGRU/Linear[linear] # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:1369:0\n",
      "  %187 : int = prim::Constant[value=-1](), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:1316:0\n",
      "  %188 : int? = prim::Constant(), scope: BiGRU\n",
      "  %189 : Float(256, 2) = aten::log_softmax(%input, %187, %188), scope: BiGRU # /Users/vsitham/opt/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/functional.py:1316:0\n",
      "  return (%189)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 4\n",
    "vocab_size = len(train_iterator.word2index)\n",
    "embedding_dim = 200\n",
    "n_layers = 2\n",
    "output_size = 2\n",
    "spatial_dropout = True\n",
    "dropout = 0.5\n",
    "\n",
    "writer = SummaryWriter('runs/exp-1')\n",
    "\n",
    "for batch in train_iterator:\n",
    "    input_seq, _, x_lengths = batch['input_seq'], batch['target'], batch['x_lengths']\n",
    "\n",
    "with SummaryWriter(comment='Model graph') as w:\n",
    "    w.add_graph(BiGRU(hidden_size, vocab_size, embedding_dim, output_size, n_layers, dropout,\n",
    "                      spatial_dropout, bidirectional=True), (input_seq, x_lengths), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The generalization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset. Use clean_review and label columns\n",
    "test_dataset = pd.read_csv('dataset/drugreview_feat_clean/test_feat_clean.csv',\n",
    "                          usecols=['clean_review', 'rating'])\n",
    "\n",
    "# Change columns order\n",
    "test_dataset['label'] = test_dataset.rating >= 5\n",
    "test_dataset = test_dataset[['clean_review', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>given sample doctor mg hours lower abdominal g...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>given medication post hysteroscopy suffered se...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>loperamide helpful diarrhea fewer caplets help...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>use claritin d seasonal allergies started taki...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>worked immediate effects noticeable long term</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_review  label\n",
       "2   given sample doctor mg hours lower abdominal g...  False\n",
       "3   given medication post hysteroscopy suffered se...   True\n",
       "4   loperamide helpful diarrhea fewer caplets help...   True\n",
       "10  use claritin d seasonal allergies started taki...   True\n",
       "15      worked immediate effects noticeable long term   True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = test_dataset.dropna()\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed vocabulary using as minimum count threashold: count = 3.00\n",
      "3069/8377 tokens has been retained\n",
      "Trimmed input strings vocabulary\n",
      "Trimmed input sequences lengths to the length of: 54\n",
      "Mapped words to indices\n",
      "Batches created\n"
     ]
    }
   ],
   "source": [
    "test_iterator = BatchIterator(test_dataset, batch_size=256, vocab_created=False, vocab=None, target_col=None,\n",
    "                              word2index=train_iterator.word2index, sos_token='<SOS>', eos_token='<EOS>',\n",
    "                              unk_token='<UNK>', pad_token='<PAD>', min_word_count=3, max_vocab_size=None,\n",
    "                              max_seq_len=0.9, use_pretrained_vectors=False, glove_path='glove/',\n",
    "                              glove_name='glove.6B.100d.txt', weights_file_name='glove/weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40b17f8404049afb1c11912f9d648f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, test_avg_loss, test_accuracy, test_conf_matrix = model.evaluate_model(test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.808. Test error: 0.435\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {:.3f}. Test error: {:.3f}'.format(test_accuracy, test_avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAFZCAYAAAB0RP9xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5wV1f3/8ddbsKCioFgARSXRWGMNsXyNsfcWk6gxtq9KbMnXkhj9fo0tURONRvlpotixYDB2RQVN7BoBCyoWECWAq4AoCliA/fz+mFm8Xpbl7t69ZWfezzzmwZ1zZ+ac3ayfe+7nnDmjiMDMzPJhsVo3wMzMqsdB38wsRxz0zcxyxEHfzCxHHPTNzHLEQd/MLEc617oBZmb1Zs608WXNZV+8R1+1V1vam3v6ZmY54p6+mVmxxnm1bkHFOOibmRWLxlq3oGIc9M3MijU66JuZ5UZkuKfvgVwzsxxxT9/MrJjTO2ZmOZLh9I6DvplZMU/ZNDPLkQz39D2Qa2aWI+7pm5kVy/BArnv61q4kdZF0v6QZku4o4zqHSBrWnm2rBUkPSTq81u2w1oloLGurZw76OSXpZ5JGSpopqSENTv/VDpf+MbAKsGJE/KStF4mIWyNil3ZozzdI+qGkkHR3UfnGafnjJV7nHEm3LOq4iNg9Im5qY3OtVhoby9vqmIN+Dkk6BbgMuIAkQPcB/grs2w6XXwN4OyLmtsO1KmUqsJWkFQvKDgfebq8KlPB/X1Z3/EeZM5KWB84DToiIuyJiVkTMiYj7I+I36TFLSrpM0vvpdpmkJdP3fihpkqRTJU1JvyUcmb53LnAWcGD6DeKo4h6xpDXTHnXndP8ISeMlfSbpXUmHFJQ/XXDe1pJGpGmjEZK2LnjvcUm/l/RMep1hknq08Gv4CrgHOCg9vxNwIHBr0e/qckkTJX0qaZSkbdPy3YD/Lfg5Xylox/mSngFmA33TsqPT9/8m6c6C6/9J0mOS6nbt9dyKxvK2Ouagnz9bAUsBd7dwzP8BWwKbABsD/YAzC95fFVge6A0cBVwpqXtEnE3y7eHvEbFsRFzXUkMkLQMMAHaPiK7A1sDLzRy3AvBgeuyKwKXAg0U99Z8BRwIrA0sAv26pbmAQcFj6elfgNeD9omNGkPwOVgBuA+6QtFREPFz0c25ccM6hQH+gKzCh6HqnAhulH2jbkvzuDo+Ish7YYRXQOK+8rY456OfPisC0RaRfDgHOi4gpETEVOJckmDWZk74/JyKGAjOB77SxPY3AhpK6RERDRLzezDF7AmMj4uaImBsRg4E3gb0LjrkhIt6OiM+BISTBeqEi4llgBUnfIQn+g5o55paI+Cit8xJgSRb9c94YEa+n58wput5skt/jpcAtwC8jYtIirme14J6+ZchHQI+m9MpC9OKbvdQJadn8axR9aMwGlm1tQyJiFkla5VigQdKDktYtoT1NbepdsP9BG9pzM3AisD3NfPOR9GtJb6QppU9Ivt20lDYCmNjSmxHxb2A8IJIPJ6tHHsi1DHkO+BLYr4Vj3icZkG3ShwVTH6WaBSxdsL9q4ZsR8UhE7Az0JOm9X1NCe5raNLmNbWpyM3A8MDTthc+Xpl9OA34KdI+IbsAMkmANsLCUTIupGkknkHxjeD+9vllVOejnTETMIBlsvVLSfpKWlrS4pN0lXZQeNhg4U9JK6YDoWSTpiLZ4GfiBpD7pIPIZTW9IWkXSvmlu/0uSNFFz3aShwDrpNNPOkg4E1gceaGObAIiId4HtSMYwinUF5pLM9Oks6SxguYL3PwTWbM0MHUnrAH8Afk6S5jlNUotpKKsRp3csS9L89Ckkg7NTSVISJ5LMaIEkMI0ERgOvAi+mZW2pazjw9/Rao/hmoF4sbcf7wHSSAHxcM9f4CNiLZCD0I5Ie8l4RMa0tbSq69tMR0dy3mEeAh0mmcU4AvuCbqZumG88+kvTioupJ02m3AH+KiFciYizJDKCbm2ZGWR3JcHpHnjhgZvZNX7wytKzAuNTGe9TtNFz39M3McsQLrpmZFavzvHw5HPTNzIrVeV6+HA76ZmbF3NM3M8uROl9KoRwdJeh7ipGZlapuZ87Ug44S9Fl7pc1r3QSrI2OnjgKgZ7f1a9wSqycNn4xpnws5vWNmliMeyDUzyxH39M3MciTDPX3fkWtmliPu6ZuZFctwT99B38ysSITn6ZuZ5UeGe/rO6ZuZ5YiDvplZsQo/OUvS9ZKmSHqtoOxiSW9KGi3pbknd0vI1JX0u6eV0u6rgnM0lvSppnKQBkhZ5N7KDvplZsco/OetGYLeisuHAhhHxXZIntp1R8N47EbFJuh1bUP434Bhg7XQrvuYCHPTNzIpVuKcfEU+SPCK0sGxYRMxNd58HVmvpGpJ6AstFxPORPAJxELDfoup20DczK1ZmT19Sf0kjC7b+rWzBfwMPFeyvJeklSU9I2jYt6w1MKjhmUlrWIs/eMTNrZxExEBjYlnMl/R8wF7g1LWoA+kTER5I2B+6RtEFb2+agb2ZWrEZr70g6AtgL2DFN2RARXwJfpq9HSXoHWAeYzDdTQKulZS1yesfMrFjlB3IXIGk34DRgn4iYXVC+kqRO6eu+JAO24yOiAfhU0pbprJ3DgHsXVY97+mZmxSp8c5akwcAPgR6SJgFnk8zWWRIYns68fD6dqfMD4DxJc4BG4NiIaBoEPp5kJlAXkjGAwnGAZjnom5kVq3B6JyIObqb4uoUceydw50LeGwls2Jq6nd4xM8sR9/TNzIpleO0dB30zs2J+cpaZWY5kuKfvnL6ZWY64p29mVszpHTOzHMlwesdB38ysmIO+mVmOJMveZJIHcs3McsQ9fTOzYk7vmJnliIO+mVmOeMqmmVmOZLin74FcM7MccU/fzKxYhqdsOuibmRXLcHrHQd/MrFiGg75z+mZmOeKevplZMU/ZNDPLj2j0QK6ZWX5kOKfvoG9mVizD6R0P5JqZ5Yh7+mZmxZzTNzPLEef0zcxyxEHfzCxHMrz2jgdyzcxyxD19M7NiTu+YmeWIZ++YmeWIb84yM7MscE/fzKyY0ztmZvkRHsg1M8sR9/TNzHLEA7lmZpYF7umbmRVzesfMLEc8kGtmliPu6ZuZ5YgHcs3MLAvc068jq/ZahYuvPI8eK61ARPD3m+/mpoGDueyaC+n77TUA6LpcVz779DP22f5ndO7cmfMv+x0bbLQunTt34u4hD3L15TfU+Kew9tar96oMuOpCVlqpBxHBLTcN4dqrbpn//i9OPIJz/nAaG/TdmunTP+FHP9mLE046CiFmzpzF6aeex5jX3qrhT9ABOb1j1TBv3jwuPPsvjBn9JsssszR3P3YLzzz+PCcdc8b8Y04/92RmfjoTgN332YklllicvbY7kKW6LMVDT9/BA3c9zOSJDbX6EawC5s6dy7lnXsSrr7zBMssuzSOP/4Mn//Ucb7/1Dr16r8oPt9+aSRPfn3/8fyZM4kd7HM6MGZ+yw07bcvFl57LnTgfV8CfoeLJ8R25V0zuSlqxmfR3N1A+nMWb0mwDMmjWbd95+l1V6rvyNY/bYdyfuv/thACKCpZfuQqdOnVhqqSWZM2cOMz+bVfV2W2VN+XAar77yBgCzZs5m7NvjWTX9uzj3gt/y+7MvIQqe9DTyhZeZMeNTAEaNeIWevVapfqM7usYob6tjVQn6kvpJehUYm+5vLOn/VaPujqr36j1Zf6N1eWXUa/PLvrfVpkybOp0J4ycC8PD9jzF79uc8+9ojPPHSg1x35c3M+OTTWjXZqmC1Pr3YaKP1eHHUaHbdYwc+aJjSYurm4EMP4J+PPlXFFlq9q1Z6ZwCwF3APQES8Imn7KtXd4Sy9TBeuuOFizj/zz8yc+XXPfa/9d+OBux6Zv//dzTagcV4j22y0G8t168rg+6/l2SdfYOKEybVotlXY0ssszXWDLues/72QeXPn8atT+nPQj45e6PFbb9uPnx36I/bd7edVbGVG1HlvvRzVSu8sFhETisrmtXSCpP6SRkoaOXDgwAo2rb507tyZK264mPv+8RDDHvzX/PJOnTqxy57bM/SeYfPL9j5gN57857PMnTuX6dM+5sUXXmHDTdavRbOtwjp37sx1gy7jrjseYOj9j7LGWqvTZ43ePPb03bwwejg9e63CsCfuZKWVewCw3gbrcMmA8zjiZyfy8cczatz6Digay9vqWLWC/kRJ/YCQ1EnSScDbLZ0QEQMjYouI2KJ///7VaWUduOCy3/HO2+9yw1W3fqN86+36MX7ce3zQMGV+WcOkD9hq2+8B0GXppdhk840YP/bdqrbXquPSK37P2LfHc/WVNwHw5pixbLT2tvT77s70++7ONLz/IbtsdwBTp0yj92o9ue7mAfzyF6cz/p3ivpaVJMM5/Wqld44jSfH0AT4EHk3LrMDm39+E/Q/cizdfH8t9/7oNgEvOv5InHn2Gvfbf9RupHYBbrh/CHwecw9CnhiCJOwffx1tjxtWi6VZB/bbcjJ8ctC9jXn+L4U/dBcCF513GP4c/2ezxJ592HN1XWJ4LLzkLgHlz57Lb9j+tWnuzIOo8cJdDhaP+dSzWXmnzWrfB6sjYqaMA6NnN6Sz7WsMnYwBU7nU+O2nvsgJj18vuL7sNlVKVnr6ka4AFfokRkZ+8jZl1HBnu6VcrvfNoweulgP2BiVWq28ysdTJ8c1ZVgn5E/L1wX9LNwNPVqNvMrNXc0293awG+TdDM6lOGg3617sj9WNL0dPsEGA6csajzzMyySNL1kqZIeq2gbAVJwyWNTf/tnpZL0gBJ4ySNlrRZwTmHp8ePlXR4KXVXPOhLErAxsFK6dY+IvhExpNJ1m5m1RUSUtZXgRmC3orLTgcciYm3gsXQfYHdg7XTrD/wNkg8J4Gzg+0A/4OymD4qWVDzoR/IbGBoR89Itu9+bzCwbKnxzVkQ8CUwvKt4XuCl9fROwX0H5oEg8D3ST1BPYFRgeEdMj4mOSDErxB8kCqnVH7suSNq1SXWZm5Skz6BcuI5NupUxPXyUimtZF/4Cvxz17883ZjpPSsoWVt6iiA7mSOkfEXGBTYISkd4BZJDdPRERs1uIFzMw6oIgYCLR50bCICEkVyYpUevbOC8BmwD4VrsfMrN3UaBmGDyX1jIiGNH3TtNDWZGD1guNWS8smAz8sKn98UZVUOr0jgIh4p7mtwnWbmbVNbRZcuw9omoFzOHBvQflh6SyeLYEZaRroEWAXSd3TAdxd0rIWVbqnv5KkUxb2ZkRcWuH6zcxar8I35EoaTNJL7yFpEsksnD8CQyQdBUwAmlbJGwrsAYwDZgNHAkTEdEm/B0akx50XEcWDwwuodNDvBCxLOyyAZGZWLZVO70TEwQt5a8dmjg3ghIVc53rg+tbUXemg3xAR51W4DjMzK1Glg757+GbW8WR4GYZKB/0FvqqYmdW97C6yWdmgX8qggplZvcnyk7OqdUeumZnVgVotrWxmVr+c3jEzy48sp3cc9M3Mirmnb2aWH5HhoO+BXDOzHHFP38ysWIZ7+g76ZmZFspzecdA3MyvmoG9mlh9Z7ul7INfMLEfc0zczK5Llnr6DvplZEQd9M7M8iew+CqRNOX1Ja0harb0bY2ZmlVVS0Jd0i6St0teHAW8Bb0s6ooJtMzOriWgsb6tnpfb0dwFGpa9PBXYGtgT+txKNMjOrpWhUWVs9KzWnv0REfCWpF7BSRDwFIKln5ZpmZlYb9d5bL0epQf8VSb8B1gQeBEg/AD6tULvMzGomPJDL0cD3gG7AmWnZNsDgSjTKzMwqo6SefkSMBX5aVHYHcEclGmVmVku5TO+ks3QWKSIGtV9zzMxqr94HY8vRUk//mBLOD8BB38wyJbL7iNyFB/2I2LaaDTEzqxdZ7umXfEeupO6SDpZ0Srq/ajqDx8zMOohS78jdFngbOAo4Ny1eF7iqQu0yM6sZ35wFlwOHRMQwSR+nZc8D/SrTLDOz2sllTr/IWhExLH3d9Ov4Cli8/ZtkZlZb9d5bL0epOf03Je1UVLYD8Fo7t8fMzCqo1J7+r4F7Jd0LdJF0JbB/upmZZUqWl2Eo9Y7cZyRtChxKMi+/AdgqIiZUsnFmZrWQyztyi0XEROACSd0j4uNFnmBm1kE1ZrinX+qUzeUl3SBpNjBN0ux0v1uF22dmVnURKmurZ6UO5F5PssLm94Hu6b/LpeVmZtZBlJre2QHoFRGfp/uvpguyTa5Ms8zMasdTNmEc0KeobDVgbPs2x8ys9iLK2+pZqUsrPwIMk3QTMBFYHTgMuLmyzTMzq74s9/Rbs7Tyf4DtC/YnAtu1e4vMzGosy7N3vLSymVmOlDxP38wsL+p92mU5Sp2n30vSEEkfSppXuFW6gWZm1ZblgdxSZ+9clR67JzCTZEnlB4HjK9QuM7OaaQyVtdWzUtM72wBrRMRMSRERoyQdCTwNXF255pmZWXsqNejPI1k/H2CGpJWAGSRz9c3MMiXLOf1Sg/4IYHfgXmA4cBswG3ixQu0yM6uZes/Ll6PUoH8oX+f//wc4DVgWuLQSjWrO2KmjqlWVdSANn4ypdRMsg+o9L1+OUtfTn17wehZwdsVaZGZWY7lM70g6q5QLRMR57decheu8RO9qVGMdxNyvkrX+5kwbX+OWWD1ZvEffWjeh7rXU01+7hPMznPkys7zKZXonIg6tZkPMzOpFlnuzXobBzKxILnv6ZmZ5leWB3FKXYTAzs3Yi6TuSXi7YPpV0kqRzJE0uKN+j4JwzJI2T9JakXdtat3v6ZmZFGit8/Yh4C9gEQFInkkfP3g0cCfwlIv5ceLyk9YGDgA2AXsCjktaJiFYvellyT1/S9pKulnRPur+ZJD9ExcwyJ1BZWyvtCLwTERNaOGZf4PaI+DIi3iV5hG2/tvxspS6tfDxwHcnTspqenvUVcH5bKjUzq2eNUd4mqb+kkQVb/xaqOwgYXLB/oqTRkq6X1D0t600Sf5tMSstardSe/qnAThHxB77+5vMGsF5bKjUzy7KIGBgRWxRsA5s7TtISwD7AHWnR34BvkaR+GoBL2rttpeb0uwJNXz2aprB25uuVN83MMqOx9SmattodeDEiPgRo+hdA0jXAA+nuZGD1gvNWS8tardSe/tPAr4vKTgCeaEulZmb1rIo5/YMpSO1I6lnw3v7Aa+nr+4CDJC0paS2SFRNeaMvPVmpP/5fAA5KOAbpKep2kl79Hy6eZmXU8lZ69AyBpGWBn4BcFxRdJ2oQko/Je03sR8bqkIcAYYC5wQltm7kDpq2xOlrQZsDXQh2RA4bm2VmpmVs/aMAOn9XUkKxavWFS20OVvIuJ82mHyTMnz9CMigGfSzczMOqCSgr6kd1nIGkQR4bVMzSxTqpHeqZVSe/pHF+33JMnzD27mWDOzDi33QT8iHisuk/QYMBS4rL0bZWZWS9XI6ddKOWvvfA44tWNmmdOY3Zhfck6/+NGJSwN7AsPavUVmZlYxpfb0ix+dOAu4ErixXVtjZlYHqnhHbtUtMuiny34OB4ZExBeVb5KZWW1l+XGJi1yGIb0B6/854JtZXjSWudWzUtfeebDwCS5mZtYxlZrTXwy4S9LTJEswzP/2ExH/XYmGmZnVSqNynNNPjQUurmRDzMzqRZZz+i0GfUkHR8TgiPhdtRpkZlZr9Z6XL8eicvpXV6UVZmZ1pFHlbfVsUUG/zptvZmatsaicfidJ29NC8I+If7Zvk8zMaivPN2ctCVzHwoN+4PV3zCxjcjuQC8zyevlmljf1npcvR6k3Z5mZWQYsqqef4c87M7PmZXnKZotBPyK6VqshZmb1Is85fTOz3MlyTt9B38ysSJbTOx7INTPLEff0zcyKZLmn76BvZlYknNM3M8sP9/TNzHIky0HfA7lmZjninr6ZWRHfnGVmliO+OcvMLEec0zczs0xwT9/MrEiWe/oO+mZmRTyQa2aWIx7INTPLkSyndzyQa2aWI+7pm5kVcU7fzCxHGjMc9h30zcyKZDmn76BvZlYku/18D+SameWKe/pmZkWc3jEzyxHfnGVmliNZnr3jnL6ZWY446NeZawZewvuTXuHllx6bX3bW705hwrsjGTliGCNHDGP33XYAYPHFF+faay7lpRcfZdTI4Wz3g61q1WyrgDMvuJQf7HkQ+/382AXeu3HwnWy4ze58/MkMAMZPmMgh/U9m0x/uzQ23/WOB4+fNm8ePjziB439zdsXbnQVR5lbPHPTrzKBBQ9hzr0MWKL98wDVs8b1d2OJ7u/DQw/8E4OijfgbAppvtxG67H8RFF52FlOFkZM7st8fOXHXpHxYob/hwKs++8CI9V1l5ftnyy3Xl9JOP5YiDD2j2WrfccS991+xTsbZmTWOZWz1z0K8zTz39b6Z//ElJx6633jr86/FnAJg69SNmfPIpW2y+cSWbZ1W0xSYbsfxyXRcov2jA1Zxy/FEUfr6v2L0bG633HTp3XnCY7oMpU3ny2Rc4YO9dK9ncTGkkytrqWdWCvhI/l3RWut9HUr9q1d/RHX/ckbw4ajjXDLyEbt2WB2D06DHsvdcudOrUiTXXXJ3NNtuI1VbvVeOWWiX986nnWHmlHqy7dt+Sz/nT5U0fEu7jlcrpnfbxV2Ar4OB0/zPgyirW32FddfUg1ll3azbfYhc++GAKF190FgA33Hg7kyc18O/nH+LSS87luedGMm/evBq31irl8y++4JpBf+fEow8t+ZzHn/k3K3Tvxgbrrl3BlllHUs0pm9+PiM0kvQQQER9LWmJhB0vqD/QHuPrqq6vUxPo0Zcq0+a+vve5W7r3nJiAZnDv1N+fMf++pJ+5l7Njx1W6eVcnEyQ1Mfv8DDjj8eAA+nDqNn/z3L7n9msvoseIKzZ7z0ugxPP708zz13Ai+/GoOs2bN5rfnXsSfzj6tmk3vcOo9L1+Oagb9OZI6kX77kbQSLfxuI2IgMLBp9/gTz618C+vUqquuzAcfTAFgv3135/XX3wKgS5elkMTs2Z+z047bMnfuXN54Y2wtm2oVtM631uLJB2+fv7/LAYfz9+sG0D1N9zXn5OOO5OTjjgTghRdHc+PgOx3wS1DveflyVDPoDwDuBlaWdD7wY+DMKtbfIdxy85Vs94Ot6NFjBd4bP5Jzz/sz2223NRtvvD4RwYQJkzju+N8CsPLKPRj64G00Njby/uQPOPzIX9W49daefnP2Hxnx0mg++eRTdtzv5xx/1KELHYyd9tF0DjzqV8ycNZvFFluMW4bcw723Xs2yyyxT5VZnQ3ZDPiiiej+epHWBHQEBj0XEGyWeGp2X6F25hlmHM/eryQDMmeZ0ln1t8R59IYkvZfmfNQ8qKzBe/t7tdTt3upqzd74FvBsRVwKvATtL6lat+s3M6omk9yS9KullSSPTshUkDZc0Nv23e1ouSQMkjZM0WtJmba23mrN37gTmSfo2cDWwOnBbFes3MytJlPm/Vtg+IjaJiC3S/dNJsiBrA4+l+wC7A2unW3/gb2392aoZ9BsjYi7wI+CKiPgN0LOK9ZuZlaSGd+TuC9yUvr4J2K+gfFAknge6SWpT/Kxm0J8j6WDgMOCBtGzxKtZvZlaScu/IldRf0siCrX8z1QQwTNKogvdXiYiG9PUHwCrp697AxIJzJ6VlrVbN2TtHAscC50fEu5LWAm6uYv1mZlVRNOV8Yf4rIiZLWhkYLunNomuEpHafaVO1oB8RY4BfFey/C/ypWvWbmZWqGnMaI2Jy+u8USXcD/YAPJfWMiIY0fTMlPXwyyThok9XSslareNCX9Cot/A4j4ruVboOZWWtU+uYsScsAi0XEZ+nrXYDzgPuAw4E/pv/em55yH3CipNuB7wMzCtJArVKNnv5eVajDzKzdVGEZhlWAu9Ol0DsDt0XEw5JGAEMkHQVMAH6aHj8U2AMYB8wmSZe3ScWDfkRMqHQdZmbtqZXTLlt//YjxwALroEfERyQ3sBaXB3BCe9RdzZuztpQ0QtJMSV9Jmifp02rVb2Zm1Z29cwVwEHAHsAXJ1M11qli/mVlJsrzKZlWfqhAR44BOETEvIm4Adqtm/WZmpajiHblVV82e/ux0/fyXJV0ENODHNZpZHXJPv30cmtZ3IjCLZM5p809xNjOrocaIsrZ6Vo15+n0i4j8Fs3i+APL7RBQzsxqqRk//nqYXku6sQn1mZmXJ8oPRq5HTL3yYQN8q1GdmVhY/LrE8sZDXZmZ1qd5n4JSjGkF/4/QmLAFdCm7IEsmNZstVoQ1mZkZ1lmHoVOk6zMzaU5anbFZznr6ZWYfgnL6ZWY44p29mliNZTu94GQQzsxxxT9/MrEjU+VIK5XDQNzMr4oFcM7McyXJO30HfzKxIlmfveCDXzCxH3NM3MyvinL6ZWY549o6ZWY5keSDXOX0zsxxxT9/MrEiWZ+846JuZFfFArplZjngg18wsR7Lc0/dArplZjrinb2ZWxAO5ZmY50uicvplZfmQ35Dvom5ktwAO5ZmaWCe7pm5kVyXJP30HfzKyIb84yM8uRLPf0ndM3M8sR9/TNzIr45iwzsxxxTt/MLEeynNN30DczK5Llnr4Hcs3McsQ9fTOzIk7vmJnliGfvmJnlSJaXVnZO38wsR9zTNzMr4vSOmVmOZDm946BvZlbEPX0zsxzJck/fA7lmZjninr6ZWRGnd+rA3K8m17oJVocW79G31k2wDMpyeqejBH3VugH1QlL/iBhY63ZYffHfRfvKck/fOf2Op3+tG2B1yX8X7Siisaytnjnom5lVmaTVJf1L0hhJr0v6n7T8HEmTJb2cbnsUnHOGpHGS3pK0a1vr7ijpHTOzqqnCKptzgVMj4kVJXYFRkoan7/0lIv5ceLCk9YGDgA2AXsCjktaJiHmtrdhBv+Nx3taa47+LdlTph6hERAPQkL7+TNIbQO8WTtkXuD0ivgTelTQO6Ac819q6nd7pYDxYZ83x30X7aiTK2iT1lzSyYFvomIukNYFNgX+nRSdKGi3peknd07LewMSC0ybR8ofEQjnom5m1s4gYGBFbFGzNfihLWha4EzgpIj4F/gZ8C9iE5JvAJe3dNqd36oCkFYHH0t1VgXnA1HS/X0R8VZOGWc1Imge8WlC0X0S8t5Bj1wQeiIgNK9+yfKjGM3IlLU4S8G+NiOiJRw8AAAXNSURBVLvSej8seP8a4IF0dzKwesHpq6VlreagXwci4iOST3YknQPMbGYgR4Ci3ueDWXv5PCI2qXUj8qrSN2el/z1fB7wREZcWlPdM8/0A+wOvpa/vA26TdCnJQO7awAttqdvpnTom6dvplK5bgdeB1SV9UvD+QZKuTV+vIumuNH/4gqQta9VuqwxJa0p6StKL6bZ1M8dskP7//3KaF147Lf95QfnVkjpV/yfoOKLM/5VgG+BQYIei6ZkXSXpV0mhge+BkgIh4HRgCjAEeBk5oy8wdcE+/I1gXOCwiRkpq6f+vAcBFEfF809d9wF/3O64ukl5OX78bEfsDU4CdI+KLNJgPBrYoOu9Y4PKIuFXSEkAnSesBBwLbRMQcSX8FDgEGVedH6XiqMHvnaZpfaWBoC+ecD5xfbt0O+vXvnYgYWcJxOwHfSb41AtBdUpeI+LxyTbMKai69szhwhaRNSMZ91mnmvOeA/5O0GnBXRIyVtCOwOTAi/fvoQvIBYjnkoF//ZhW8buSbvYOlCl4LD/pm3cnAh8DGJKnZL4oPiIjbJP0b2BMYKukXJH8bN0XEGdVsbEdWhZuzasY5/Q4kHcT9WNLakhYjGehp8ihwQtNO2hu0bFkeaEj/Dg4FFsjLS+oLjI+IAcC9wHdJZob9WNLK6TErSFqjes3ueCKirK2eOeh3PL8FHgGeJblBo8kJwDbp4N0Y4JhaNM4q6q/A4ZJeIRnrmdXMMT8FXkvHAzYEBkXEGOBMYFg6QDgc6FmlNndIjRFlbfVM9f6pZGZWbd2X/XZZgfHjmePqdjl49/TNzHLEA7lmZkWyPJDroG9mViTLaW8HfTOzIvU+GFsO5/TNzHLEQd/qTrrGTDQtOyHpIUmHt+E6fSTN9Doz1lpVWHunZpzesTaT9B6wCsmSALOAh4ATI2Jme9YTEbu3oj1HR8Sj6Xn/AZZtz7ZYPji9Y7Zwe0fEssBmJIt/nVn4phL+O7MOxXfkmi1CREwm6elvKOlxSedLegaYDfSVtLyk6yQ1SJos6Q9NaRdJnST9WdI0SeNJ1o2ZL73e0QX7x0h6Q9Jn6dLTm0m6GegD3J+mdE5rJk3US9J9kqZLGifpmIJrniNpiKRB6XVfl7RFwfu/Tdv9maS30kXMLKOynN5x0Ld2IWl1YA/gpbToUKA/0BWYANwIzAW+TfI80F2ApkB+DLBXWr4F8OMW6vkJcA5wGLAcsA/wUUQcCvyH9JtHRFzUzOm3kyxd0Sut4wJJOxS8v096TDeSh1Zckdb5HeBE4HsR0RXYFXhvkb8UszrkoG/luid9sMvTwBPABWn5jRHxekTMBVYg+UA4KSJmRcQU4C/AQemxPwUui4iJETEduLCF+o4meW7AiEiMi4gJi2pk+qG0DfDbiPgiIl4GriX58GjydEQMTR9OcTPJapaQjFksCawvafGIeC8i3llUndZxZTm944FcK9d+TQOnTdI12ycWFK1BshZ8Q8F6/4sVHNOr6PiWgvjqQFsCbi9gekR8VlRP4UNIPih4PRtYSlLniBgn6SSSbxgbSHoEOCUi3m9DO6wDqPfAXQ739K1SCv+rmQh8CfSIiG7ptlxEbJC+38A3H/rcp4XrTgS+VUKdxd4HVpDUtaiekh4uHRG3RcR/kXyABfCnUs6zjinK3OqZe/pWcRHRIGkYcImk3wEzgbWA1SLiCZJnf/5K0gMkUz9Pb+Fy1wKXSnoaeJHkA2BOmuL5EOi7kDZMlPQscKGkX5M8deookscGtijN6fcGniF5cMnnNLOWvWXH3K8m1+0qmeVyT9+q5TBgCZIHO38M/IOv13S/huQZAa+QBPK7FnaRiLiD5DmhtwGfAfeQjBlAMhZwpqRP0sBe7GBgTZJe/93A2cWpqYVYEvgjMI0kBbQy4KdQWYfk9fTNzHLEPX0zsxxx0DczyxEHfTOzHHHQNzPLEQd9M7MccdA3M8sRB30zsxxx0DczyxEHfTOzHPn/ydMKzpdwouAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(6,6))\n",
    "ax = sns.heatmap(test_conf_matrix, fmt='d', annot=True, linewidths=1, square=True)\n",
    "ax.set_xlabel('Predictions', size=12)\n",
    "ax.set_ylabel('True labels', size=12) \n",
    "ax.set_title('Confusion Matrix', size=12); \n",
    "ax.xaxis.set_ticklabels(['True', 'False'])\n",
    "ax.yaxis.set_ticklabels(['True', 'False'])\n",
    "ax.set_ylim(2,0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generalization accuracy of the biGRU model equals 0.808. As we can see on the above plot of the confusion matrix the both, positive and negative classes were similarly numerous, and the prediction mistakes amount (TN, FP) is also very similar, so model learned both classes in the same detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
